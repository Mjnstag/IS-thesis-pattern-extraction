{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hanoi_scenario_dir': 'C:\\\\Users\\\\mjnst\\\\Desktop\\\\Thesis\\\\Hanoi_CMH\\\\Scenario-1', 'RUG_dir': 'C:\\\\Users\\\\mjnst\\\\Desktop\\\\Thesis\\\\RUG_data_5years', 'RUG_raw_csv': 'C:\\\\Users\\\\mjnst\\\\Desktop\\\\Thesis\\\\rug_csv.csv', 'RUG_timeseries': 'C:\\\\Users\\\\mjnst\\\\Desktop\\\\Thesis\\\\rug_timeseries.pkl', 'RUG_obfuscated': 'C:\\\\Users\\\\mjnst\\\\Desktop\\\\Thesis\\\\obfuscated_data.pkl', 'RUG_no_outliers': 'C:\\\\Users\\\\mjnst\\\\Desktop\\\\Thesis\\\\obfuscated_data_rm_outlier.pkl'}\n"
     ]
    }
   ],
   "source": [
    "with open(\"options.txt\", 'r') as f:\n",
    "    options = f.readlines()\n",
    "    options = {option.split(\"=\")[0]: option.split(\"=\")[1].strip() for option in options}\n",
    "print(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUG = pd.read_pickle(options['RUG_no_outliers'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing and Transforming Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUG.interpolate(method='linear', inplace=True, limit=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(col_name):\n",
    "    df = RUG[col_name].copy()\n",
    "    \n",
    "    groups = df.groupby(pd.Grouper(freq='D'))\n",
    "\n",
    "    # get the calender date of the groups\n",
    "    days = list(groups.first().index.strftime('%Y:%m:%d'))\n",
    "\n",
    "    gro = [groups.get_group(x).reset_index(drop=True) for x in groups.groups]\n",
    "\n",
    "    temp = pd.concat(gro, axis=1, keys=days)\n",
    "\n",
    "    temp.index = pd.date_range(\"00:00\", \"23:59\", freq=\"1min\").strftime('%H:%M')\n",
    "\n",
    "    # drop all columns of temp dataframe which contain nan values\n",
    "    temp.dropna(axis=1, how='any', inplace=True)\n",
    "    return temp[::10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(data):\n",
    "\n",
    "    temp = data.copy()\n",
    "\n",
    "    train_percentage = 0.8\n",
    "    train_size = int(len(temp.columns) * train_percentage)\n",
    "    \n",
    "    train = temp.iloc[:, :train_size]\n",
    "    test = temp.iloc[:, train_size:]\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "    scaled_list_train = [train[col] for col in train]\n",
    "    scaled_list_train = scaler.fit_transform(scaled_list_train)\n",
    "\n",
    "    scaled_list_test = [test[col] for col in test]\n",
    "    scaled_list_test = scaler.transform(scaled_list_test)\n",
    "\n",
    "    return scaler, scaled_list_train, scaled_list_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pca(data):\n",
    "    temp = data.copy()\n",
    "    \n",
    "    pca = PCA(n_components=0.85, svd_solver='full')\n",
    " \n",
    "    # Fit and transform data\n",
    "    pca_features = pca.fit_transform(temp)\n",
    "\n",
    "    return pca_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_kmeans(pca_data, scaled_train, scaled_test, clusters=4):\n",
    "    temp_pca_data = pca_data.copy()\n",
    "    temp_scaled_train = scaled_train.copy()\n",
    "    temp_scaled_test = scaled_test.copy()\n",
    "\n",
    "    kmeans_pca = TimeSeriesKMeans(n_clusters=clusters, metric=\"dtw\", n_jobs=-1).fit(temp_pca_data)\n",
    "    train_pca_features = kmeans_pca.labels_\n",
    "    test_pca_features = kmeans_pca.predict(temp_scaled_test)\n",
    "\n",
    "    return train_pca_features, test_pca_features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Num of clusters per column\n",
    "\n",
    "based on elbow method and silhouette score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = [4, 4, 3, 3, 4, 4, 4, 3, 3, 4, 3, 4, 4]\n",
    "\n",
    "n_iterations = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_results = []\n",
    "for location, clust_n in zip(RUG.columns, clusters):\n",
    "    print(location)\n",
    "    indice_results = []\n",
    "    for it in range(n_iterations):\n",
    "        print(it)\n",
    "        data = get_data(location)\n",
    "\n",
    "        scaler, scaled_list_train, scaled_list_test = scale_data(data)\n",
    "        \n",
    "        pca_features = create_pca(scaled_list_train)\n",
    "\n",
    "        train_pca_features, test_pca_features = create_kmeans(pca_features, scaled_list_train, scaled_list_test, clust_n)\n",
    "        # print(Counter(train_pca_features), Counter(test_pca_features))\n",
    "        indice_results.append(train_pca_features)\n",
    "    complete_results.append(indice_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_stabilty = {}\n",
    "# check how many indices intersect between all combinations of labels\n",
    "for column, name in zip(complete_results, RUG.columns):\n",
    "    print(name)\n",
    "    run_stability = []\n",
    "    \n",
    "\n",
    "    run_combinations = combinations(np.arange(n_iterations), 2)\n",
    "    for run_base, run_compare in run_combinations:\n",
    "        print(f\"Run {run_base} -> Run {run_compare}\")\n",
    "\n",
    "        run_base_stats = dict(Counter(column[run_base]))\n",
    "        run_compare_stats = dict(Counter(column[run_compare]))\n",
    "\n",
    "        label_combinations = set(combinations(np.concatenate((np.unique(column[run_base]), np.unique(column[run_compare]))), 2))\n",
    "        # print(label_combinations)\n",
    "        highest = []\n",
    "        for label_base in np.unique(column[run_base]):\n",
    "            temp_high = 0\n",
    "            for label_compare in np.unique(column[run_compare]):\n",
    "                \n",
    "                if (label_base, label_compare)  in label_combinations:\n",
    "                    res = len(np.intersect1d((column[run_base] == label_base).nonzero(), (column[run_compare] == label_compare).nonzero()))\n",
    "                    # print(run_base_stats[label_base])\n",
    "                    # print(label_base, run_base_stats, label_compare, run_compare_stats, res)\n",
    "                    res2 = (res/run_base_stats[label_base]*100 + res/run_compare_stats[label_compare]*100)/2\n",
    "                    # print(res2)\n",
    "                    if res2 > temp_high:\n",
    "                        temp_high = res2\n",
    "                highest.append(temp_high)\n",
    "        run_stability.append(np.mean(highest))\n",
    "    # break\n",
    "    col_stabilty[name] = np.mean(run_stability)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(col_stabilty, index=[0]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
