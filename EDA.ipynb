{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"options.txt\", 'r') as f:\n",
    "    options = f.readlines()\n",
    "    options = {option.split(\"=\")[0]: option.split(\"=\")[1].strip() for option in options}\n",
    "print(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUG = pd.read_json(f'{options[\"RUG_dir\"]}/summary.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(RUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUG.to_pickle(f'{options[\"RUG_dir\"]}/summary.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUG_1 = pd.read_pickle(f'{options[\"RUG_dir\"]}/summary.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_dir = options[\"hanoi_scenario_dir\"]\n",
    "# print(scenario_dir)\n",
    "# Read each CSV file in dir \"path/to/root_dir\"\n",
    "\n",
    "def read_files_dataframe(scenario_dir):\n",
    "    dfs = []\n",
    "    for subfolder in [\"Demands\", \"Flows\", \"Pressures\"]:\n",
    "        for file in Path(scenario_dir).glob(f\"{subfolder}/*.csv\"):\n",
    "            dfs.append(pd.read_csv(file, index_col=0, header=0, names=[\"Index\", f\"{subfolder}_{file.stem}\"]))\n",
    "    dfs = pd.concat(dfs, axis=1)\n",
    "    # dfs.index = pd.read_csv()\n",
    "    index = pd.read_csv(f'{scenario_dir}/Timestamps.csv', index_col=0, header=0)\n",
    "    dfs.index = index.Timestamp\n",
    "    return dfs\n",
    "\n",
    "# Put the dataframes to a single dataframe\n",
    "# df = pd.concat(dfs, axis=1)\n",
    "# print(dfs)\n",
    "df_15 = read_files_dataframe(scenario_dir)\n",
    "df_1 = read_files_dataframe(scenario_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nodes of different scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, )\n",
    "df_15.Demands_Node_6.plot(ax=axs[1], xlabel=\"Time\", ylabel=\"Demand\", title=\"Scenario 15\",figsize=(15, 9))\n",
    "df_1.Demands_Node_6.plot(ax=axs[0], xlabel=\"Time\", ylabel=\"Demand\", title=\"Scenario 1\")\n",
    "fig.suptitle('Demand at Node 6', fontsize=16)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subset of data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, )\n",
    "df_1.Demands_Node_6[:3000].plot(ax=axs[0], xlabel=\"Time\", ylabel=\"Demand\", title=\"Node 6\", figsize=(10, 7))\n",
    "df_1.Demands_Node_29[:3000].plot(ax=axs[1], xlabel=\"Time\", ylabel=\"Demand\", title=\"Node 29\")\n",
    "df_1.Demands_Node_13[:3000].plot(ax=axs[2], xlabel=\"Time\", ylabel=\"Demand\", title=\"Node 13\")\n",
    "df_1.Demands_Node_3[:3000].plot(ax=axs[3], xlabel=\"Time\", ylabel=\"Demand\", title=\"Node 3\")\n",
    "fig.suptitle('Demand at different nodes', fontsize=16)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, )\n",
    "df_1.Pressures_Node_6[:3000].plot(ax=axs[0], xlabel=\"Time\", ylabel=\"Demand\", title=\"Node 6\", figsize=(10, 7))\n",
    "df_1.Pressures_Node_2[:3000].plot(ax=axs[1], xlabel=\"Time\", ylabel=\"Demand\", title=\"Node 2\")\n",
    "df_1.Pressures_Node_13[:3000].plot(ax=axs[2], xlabel=\"Time\", ylabel=\"Demand\", title=\"Node 13\")\n",
    "df_1.Pressures_Node_3[:3000].plot(ax=axs[3], xlabel=\"Time\", ylabel=\"Demand\", title=\"Node 3\")\n",
    "fig.suptitle('Demand at different nodes', fontsize=16)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df_15.Demands_Node_6.iloc[:1000].plot()\n",
    "df_15.Demands_Node_6.iloc[:1000].ewm(span=6).mean().plot(ax=ax)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hanoi water network (with flow directions and element ids)\n",
    "\n",
    "![alt text](img/hanoi_wn.png \"Title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.boxplot(column=['Demands_Node_6'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_15.Demands_Node_10.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "recorded = only existing values\n",
    "summary json is actual existing sensor value + interpolated sensor values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
