{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import datetime\n",
    "\n",
    "import os, math\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Algorithms\n",
    "from tslearn.barycenters import dtw_barycenter_averaging\n",
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hanoi_scenario_dir': 'C:\\\\Users\\\\mjnst\\\\Desktop\\\\Thesis\\\\Hanoi_CMH\\\\Scenario-1', 'RUG_dir': 'C:\\\\Users\\\\mjnst\\\\Desktop\\\\Thesis\\\\RUG_data_5years', 'RUG_raw_csv': 'C:\\\\Users\\\\mjnst\\\\Desktop\\\\Thesis\\\\rug_csv.csv', 'RUG_timeseries': 'C:\\\\Users\\\\mjnst\\\\Desktop\\\\Thesis\\\\rug_timeseries.pkl', 'RUG_obfuscated': 'C:\\\\Users\\\\mjnst\\\\Desktop\\\\Thesis\\\\obfuscated_data.pkl', 'RUG_no_outliers': 'C:\\\\Users\\\\mjnst\\\\Desktop\\\\Thesis\\\\obfuscated_data_rm_outlier.pkl'}\n"
     ]
    }
   ],
   "source": [
    "with open(\"options.txt\", 'r') as f:\n",
    "    options = f.readlines()\n",
    "    options = {option.split(\"=\")[0]: option.split(\"=\")[1].strip() for option in options}\n",
    "print(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUG = pd.read_pickle(options[\"RUG_no_outliers\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing and Transforming Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUG.interpolate(method='linear', inplace=True, limit=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_groups(data):\n",
    "    data_copy = data.copy()\n",
    "    groups = data_copy.groupby(pd.Grouper(freq='D'))\n",
    "\n",
    "    # get the calender date of the groups\n",
    "    days = list(groups.first().index.strftime('%Y:%m:%d'))\n",
    "\n",
    "    gro = [groups.get_group(x).reset_index(drop=True) for x in groups.groups]\n",
    "\n",
    "    temp = pd.concat(gro, axis=1, keys=days)\n",
    "\n",
    "    temp.index = pd.date_range(\"00:00\", \"23:59\", freq=\"1min\").strftime('%H:%M')\n",
    "\n",
    "    # drop all columns of temp dataframe which contain nan values\n",
    "    temp.dropna(axis=1, how='any', inplace=True)\n",
    "\n",
    "    return temp[::10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(data):\n",
    "    data_copy = data.copy()\n",
    "    train_percentage = 0.8\n",
    "    train_size = int(len(data_copy.columns) * train_percentage)\n",
    "\n",
    "    train = data_copy.iloc[:, :train_size]\n",
    "    test = data_copy.iloc[:, train_size:]\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "    scaled_list_train = [train[col] for col in train]\n",
    "    scaled_list_train = scaler.fit_transform(scaled_list_train)\n",
    "    \n",
    "    scaled_list_test = [test[col] for col in test]\n",
    "    scaled_list_test = scaler.transform(scaled_list_test)\n",
    "\n",
    "    return scaled_list_train, scaled_list_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pca(data):\n",
    "    data_copy = data.copy()\n",
    "    \n",
    "    pca = PCA(n_components=0.85, svd_solver='full')\n",
    "    \n",
    "    # Fit and transform data\n",
    "    pca_features = pca.fit_transform(data_copy)\n",
    "\n",
    "    return pca_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_kmeans(pca_data, scaled_train, scaled_test, clusters=4):\n",
    "    temp_pca_data = pca_data.copy()\n",
    "    temp_scaled_train = scaled_train.copy()\n",
    "    temp_scaled_test = scaled_test.copy()\n",
    "\n",
    "    kmeans_pca = TimeSeriesKMeans(n_clusters=clusters, metric=\"dtw\", n_jobs=-1).fit(temp_pca_data)\n",
    "    train_pca_features = kmeans_pca.predict(temp_scaled_train)\n",
    "    test_pca_features = kmeans_pca.predict(temp_scaled_test)\n",
    "\n",
    "    return train_pca_features, test_pca_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scores(scaled_list_train, train_lab, test_lab, column):\n",
    "    fig, ax = plt.subplots((len(set(train_lab))))\n",
    "    fig.suptitle(column)\n",
    "    for pos, label in enumerate(set(train_lab)):\n",
    "        values = scaled_list_train[(train_lab== label).nonzero()[0]]\n",
    "        for value in values:\n",
    "            ax[pos].plot(value,c=\"gray\",alpha=0.4)\n",
    "        ax[pos].plot(np.average(values,axis=0),c=\"red\")\n",
    "    fig.tight_layout()  \n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_cluster(column, n_cluster):\n",
    "    grouped_data = create_groups(RUG[column])\n",
    "\n",
    "    scaled_list_train, scaled_list_test = scale_data(grouped_data)\n",
    "\n",
    "    pca_features = create_pca(scaled_list_train)\n",
    "\n",
    "    a = n_cluster\n",
    "    while True:\n",
    "        train_lab, test_lab = create_kmeans(pca_features, scaled_list_train, scaled_list_test, n_cluster)\n",
    "        if len(set(train_lab)) == n_cluster:\n",
    "            break\n",
    "        print(\"n_cluster: \", n_cluster, \" =! \", len(set(train_lab)))\n",
    "    plot_scores(scaled_list_train, train_lab, test_lab, column)\n",
    "    # plot_scores(column, wcss, silhouette_scores, n_cluster)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = [4, 4, 3, 3, 4, 4, 4, 3, 3, 4, 3, 4, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location 1 - flow\n",
      "n_cluster:  4  =!  2\n",
      "n_cluster:  4  =!  3\n",
      "n_cluster:  4  =!  3\n",
      "n_cluster:  4  =!  2\n",
      "n_cluster:  4  =!  3\n",
      "n_cluster:  4  =!  3\n",
      "n_cluster:  4  =!  3\n",
      "n_cluster:  4  =!  2\n",
      "n_cluster:  4  =!  3\n",
      "n_cluster:  4  =!  3\n",
      "n_cluster:  4  =!  3\n",
      "n_cluster:  4  =!  3\n",
      "n_cluster:  4  =!  3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[93], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m column, n_cluster \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(RUG\u001b[39m.\u001b[39mcolumns, clusters):\n\u001b[0;32m      2\u001b[0m     \u001b[39mprint\u001b[39m(column)\n\u001b[1;32m----> 3\u001b[0m     average_cluster(column, n_cluster)\n",
      "Cell \u001b[1;32mIn[91], line 10\u001b[0m, in \u001b[0;36maverage_cluster\u001b[1;34m(column, n_cluster)\u001b[0m\n\u001b[0;32m      8\u001b[0m a \u001b[39m=\u001b[39m n_cluster\n\u001b[0;32m      9\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m---> 10\u001b[0m     train_lab, test_lab \u001b[39m=\u001b[39m create_kmeans(pca_features, scaled_list_train, scaled_list_test, n_cluster)\n\u001b[0;32m     11\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mset\u001b[39m(train_lab)) \u001b[39m==\u001b[39m n_cluster:\n\u001b[0;32m     12\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[80], line 6\u001b[0m, in \u001b[0;36mcreate_kmeans\u001b[1;34m(pca_data, scaled_train, scaled_test, clusters)\u001b[0m\n\u001b[0;32m      3\u001b[0m temp_scaled_train \u001b[39m=\u001b[39m scaled_train\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m      4\u001b[0m temp_scaled_test \u001b[39m=\u001b[39m scaled_test\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m----> 6\u001b[0m kmeans_pca \u001b[39m=\u001b[39m TimeSeriesKMeans(n_clusters\u001b[39m=\u001b[39;49mclusters, metric\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mdtw\u001b[39;49m\u001b[39m\"\u001b[39;49m, n_jobs\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39;49mfit(temp_pca_data)\n\u001b[0;32m      7\u001b[0m train_pca_features \u001b[39m=\u001b[39m kmeans_pca\u001b[39m.\u001b[39mpredict(temp_scaled_train)\n\u001b[0;32m      8\u001b[0m test_pca_features \u001b[39m=\u001b[39m kmeans_pca\u001b[39m.\u001b[39mpredict(temp_scaled_test)\n",
      "File \u001b[1;32mc:\\Users\\mjnst\\anaconda3\\envs\\thesis\\lib\\site-packages\\tslearn\\clustering\\kmeans.py:780\u001b[0m, in \u001b[0;36mTimeSeriesKMeans.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    778\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mInit \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (n_successful \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m))\n\u001b[0;32m    779\u001b[0m n_attempts \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m--> 780\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_one_init(X_, x_squared_norms, rs)\n\u001b[0;32m    781\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minertia_ \u001b[39m<\u001b[39m min_inertia:\n\u001b[0;32m    782\u001b[0m     best_correct_centroids \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcluster_centers_\u001b[39m.\u001b[39mcopy()\n",
      "File \u001b[1;32mc:\\Users\\mjnst\\anaconda3\\envs\\thesis\\lib\\site-packages\\tslearn\\clustering\\kmeans.py:665\u001b[0m, in \u001b[0;36mTimeSeriesKMeans._fit_one_init\u001b[1;34m(self, X, x_squared_norms, rs)\u001b[0m\n\u001b[0;32m    663\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose:\n\u001b[0;32m    664\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m%.3f\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minertia_, end\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m --> \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 665\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_centroids(X)\n\u001b[0;32m    667\u001b[0m \u001b[39mif\u001b[39;00m numpy\u001b[39m.\u001b[39mabs(old_inertia \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minertia_) \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtol:\n\u001b[0;32m    668\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mjnst\\anaconda3\\envs\\thesis\\lib\\site-packages\\tslearn\\clustering\\kmeans.py:713\u001b[0m, in \u001b[0;36mTimeSeriesKMeans._update_centroids\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    711\u001b[0m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_clusters):\n\u001b[0;32m    712\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetric \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdtw\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 713\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcluster_centers_[k] \u001b[39m=\u001b[39m dtw_barycenter_averaging(\n\u001b[0;32m    714\u001b[0m             X\u001b[39m=\u001b[39;49mX[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabels_ \u001b[39m==\u001b[39;49m k],\n\u001b[0;32m    715\u001b[0m             barycenter_size\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    716\u001b[0m             init_barycenter\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcluster_centers_[k],\n\u001b[0;32m    717\u001b[0m             metric_params\u001b[39m=\u001b[39;49mmetric_params,\n\u001b[0;32m    718\u001b[0m             verbose\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    719\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetric \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msoftdtw\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    720\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcluster_centers_[k] \u001b[39m=\u001b[39m softdtw_barycenter(\n\u001b[0;32m    721\u001b[0m             X\u001b[39m=\u001b[39mX[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabels_ \u001b[39m==\u001b[39m k],\n\u001b[0;32m    722\u001b[0m             max_iter\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_iter_barycenter,\n\u001b[0;32m    723\u001b[0m             init\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcluster_centers_[k],\n\u001b[0;32m    724\u001b[0m             \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmetric_params)\n",
      "File \u001b[1;32mc:\\Users\\mjnst\\anaconda3\\envs\\thesis\\lib\\site-packages\\tslearn\\barycenters\\dba.py:498\u001b[0m, in \u001b[0;36mdtw_barycenter_averaging\u001b[1;34m(X, barycenter_size, init_barycenter, max_iter, tol, weights, metric_params, verbose, n_init)\u001b[0m\n\u001b[0;32m    496\u001b[0m \u001b[39mif\u001b[39;00m verbose:\n\u001b[0;32m    497\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAttempt \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m))\n\u001b[1;32m--> 498\u001b[0m bary, loss \u001b[39m=\u001b[39m dtw_barycenter_averaging_one_init(\n\u001b[0;32m    499\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m    500\u001b[0m     barycenter_size\u001b[39m=\u001b[39;49mbarycenter_size,\n\u001b[0;32m    501\u001b[0m     init_barycenter\u001b[39m=\u001b[39;49minit_barycenter,\n\u001b[0;32m    502\u001b[0m     max_iter\u001b[39m=\u001b[39;49mmax_iter,\n\u001b[0;32m    503\u001b[0m     tol\u001b[39m=\u001b[39;49mtol,\n\u001b[0;32m    504\u001b[0m     weights\u001b[39m=\u001b[39;49mweights,\n\u001b[0;32m    505\u001b[0m     metric_params\u001b[39m=\u001b[39;49mmetric_params,\n\u001b[0;32m    506\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose\n\u001b[0;32m    507\u001b[0m )\n\u001b[0;32m    508\u001b[0m \u001b[39mif\u001b[39;00m loss \u001b[39m<\u001b[39m best_cost:\n\u001b[0;32m    509\u001b[0m     best_cost \u001b[39m=\u001b[39m loss\n",
      "File \u001b[1;32mc:\\Users\\mjnst\\anaconda3\\envs\\thesis\\lib\\site-packages\\tslearn\\barycenters\\dba.py:590\u001b[0m, in \u001b[0;36mdtw_barycenter_averaging_one_init\u001b[1;34m(X, barycenter_size, init_barycenter, max_iter, tol, weights, metric_params, verbose)\u001b[0m\n\u001b[0;32m    588\u001b[0m cost_prev, cost \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39minf, numpy\u001b[39m.\u001b[39minf\n\u001b[0;32m    589\u001b[0m \u001b[39mfor\u001b[39;00m it \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(max_iter):\n\u001b[1;32m--> 590\u001b[0m     list_p_k, cost \u001b[39m=\u001b[39m _mm_assignment(X_, barycenter, weights, metric_params)\n\u001b[0;32m    591\u001b[0m     diag_sum_v_k, list_w_k \u001b[39m=\u001b[39m _mm_valence_warping(list_p_k, barycenter_size,\n\u001b[0;32m    592\u001b[0m                                                  weights)\n\u001b[0;32m    593\u001b[0m     \u001b[39mif\u001b[39;00m verbose:\n",
      "File \u001b[1;32mc:\\Users\\mjnst\\anaconda3\\envs\\thesis\\lib\\site-packages\\tslearn\\barycenters\\dba.py:214\u001b[0m, in \u001b[0;36m_mm_assignment\u001b[1;34m(X, barycenter, weights, metric_params)\u001b[0m\n\u001b[0;32m    212\u001b[0m list_p_k \u001b[39m=\u001b[39m []\n\u001b[0;32m    213\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n):\n\u001b[1;32m--> 214\u001b[0m     path, dist_i \u001b[39m=\u001b[39m dtw_path(barycenter, X[i], \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmetric_params)\n\u001b[0;32m    215\u001b[0m     cost \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m dist_i \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m \u001b[39m*\u001b[39m weights[i]\n\u001b[0;32m    216\u001b[0m     list_p_k\u001b[39m.\u001b[39mappend(path)\n",
      "File \u001b[1;32mc:\\Users\\mjnst\\anaconda3\\envs\\thesis\\lib\\site-packages\\tslearn\\metrics\\dtw_variants.py:190\u001b[0m, in \u001b[0;36mdtw_path\u001b[1;34m(s1, s2, global_constraint, sakoe_chiba_radius, itakura_max_slope)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"Compute Dynamic Time Warping (DTW) similarity measure between\u001b[39;00m\n\u001b[0;32m    112\u001b[0m \u001b[39m(possibly multidimensional) time series and return both the path and the\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \u001b[39msimilarity.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    187\u001b[0m \n\u001b[0;32m    188\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    189\u001b[0m s1 \u001b[39m=\u001b[39m to_time_series(s1, remove_nans\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m--> 190\u001b[0m s2 \u001b[39m=\u001b[39m to_time_series(s2, remove_nans\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(s1) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(s2) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    193\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    194\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mOne of the input time series contains only nans or has zero length.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\mjnst\\anaconda3\\envs\\thesis\\lib\\site-packages\\tslearn\\utils\\utils.py:152\u001b[0m, in \u001b[0;36mto_time_series\u001b[1;34m(ts, remove_nans)\u001b[0m\n\u001b[0;32m    150\u001b[0m     ts_out \u001b[39m=\u001b[39m ts_out\u001b[39m.\u001b[39mastype(\u001b[39mfloat\u001b[39m)\n\u001b[0;32m    151\u001b[0m \u001b[39mif\u001b[39;00m remove_nans:\n\u001b[1;32m--> 152\u001b[0m     ts_out \u001b[39m=\u001b[39m ts_out[:ts_size(ts_out)]\n\u001b[0;32m    153\u001b[0m \u001b[39mreturn\u001b[39;00m ts_out\n",
      "File \u001b[1;32mc:\\Users\\mjnst\\anaconda3\\envs\\thesis\\lib\\site-packages\\tslearn\\utils\\utils.py:420\u001b[0m, in \u001b[0;36mts_size\u001b[1;34m(ts)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mts_size\u001b[39m(ts):\n\u001b[0;32m    387\u001b[0m     \u001b[39m\"\"\"Returns actual time series size.\u001b[39;00m\n\u001b[0;32m    388\u001b[0m \n\u001b[0;32m    389\u001b[0m \u001b[39m    Final timesteps that have `NaN` values for all dimensions will be removed\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[39m    3\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 420\u001b[0m     ts_ \u001b[39m=\u001b[39m to_time_series(ts)\n\u001b[0;32m    421\u001b[0m     sz \u001b[39m=\u001b[39m ts_\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[0;32m    422\u001b[0m     \u001b[39mwhile\u001b[39;00m sz \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m numpy\u001b[39m.\u001b[39mall(numpy\u001b[39m.\u001b[39misnan(ts_[sz \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m])):\n",
      "File \u001b[1;32mc:\\Users\\mjnst\\anaconda3\\envs\\thesis\\lib\\site-packages\\tslearn\\utils\\utils.py:146\u001b[0m, in \u001b[0;36mto_time_series\u001b[1;34m(ts, remove_nans)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mto_time_series\u001b[39m(ts, remove_nans\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m    112\u001b[0m     \u001b[39m\"\"\"Transforms a time series so that it fits the format used in ``tslearn``\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \u001b[39m    models.\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[39m    to_time_series_dataset : Transforms a dataset of time series\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 146\u001b[0m     ts_out \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39;49marray(ts, copy\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    147\u001b[0m     \u001b[39mif\u001b[39;00m ts_out\u001b[39m.\u001b[39mndim \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    148\u001b[0m         ts_out \u001b[39m=\u001b[39m ts_out\u001b[39m.\u001b[39mreshape((\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for column, n_cluster in zip(RUG.columns, clusters):\n",
    "    print(column)\n",
    "    average_cluster(column, n_cluster)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
