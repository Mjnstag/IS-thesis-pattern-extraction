{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"options.txt\", 'r') as f:\n",
    "    options = f.readlines()\n",
    "    options = {option.split(\"=\")[0]: option.split(\"=\")[1].strip() for option in options}\n",
    "print(options)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load csv files from scenario from directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_dir = options[\"hanoi_scenario_dir\"]\n",
    "# print(scenario_dir)\n",
    "# Read each CSV file in dir \"path/to/root_dir\"\n",
    "\n",
    "def read_files_dataframe(scenario_dir):\n",
    "    dfs = []\n",
    "    for subfolder in [\"Demands\", \"Flows\", \"Pressures\"]:\n",
    "        for file in Path(scenario_dir).glob(f\"{subfolder}/*.csv\"):\n",
    "            dfs.append(pd.read_csv(file, index_col=0, header=0, names=[\"Index\", f\"{subfolder}_{file.stem}\"]))\n",
    "    return pd.concat(dfs, axis=1)\n",
    "\n",
    "# Put the dataframes to a single dataframe\n",
    "# df = pd.concat(dfs, axis=1)\n",
    "# print(dfs)\n",
    "df = read_files_dataframe(scenario_dir)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files_scaled(scenario_dir):\n",
    "    dfs = []\n",
    "    for subfolder in [\"Demands\", \"Flows\", \"Pressures\"]:\n",
    "        dfs_temp = []\n",
    "        for file in Path(scenario_dir).glob(f\"{subfolder}/*.csv\"):\n",
    "            dfs_temp.append(pd.read_csv(file, index_col=0, header=0, names=[\"Index\", f\"{subfolder}_{file.stem}\"]))\n",
    "        dfs_temp_trans = pd.concat(dfs_temp, axis=1)\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(dfs_temp_trans)\n",
    "        dfs.append(scaler.transform(dfs_temp_trans))\n",
    "\n",
    "    return np.concatenate(dfs, axis=1)\n",
    "data_scaled = read_files_scaled(scenario_dir)\n",
    "data_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.Demands_Node_1.iloc[:1000].plot()\n",
    "ax = df.Demands_Node_1.iloc[:1000].plot()\n",
    "df.Demands_Node_1.iloc[:1000].ewm(span=12).mean().plot(ax=ax)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for any NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in dfs:\n",
    "#     if i.isna().any():\n",
    "#         display(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().any().value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(30)\n",
    "pca_features = pca.fit_transform(df)\n",
    "print('Shape before PCA: ', df.shape)\n",
    "print('Shape after PCA: ', pca_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in sorted(list(pca.explained_variance_), reverse=True)[:10]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(\n",
    "    range(1,len(pca.explained_variance_)+1),\n",
    "    pca.explained_variance_\n",
    "    )\n",
    " \n",
    "plt.xlabel('PCA Feature')\n",
    "plt.ylabel('Explained variance')\n",
    "plt.title('Feature Explained Variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
